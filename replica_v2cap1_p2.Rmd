---
title: "oct01"
author: "VLD"
date: "10/1/2020"
output:
  slidy_presentation: default
  beamer_presentation: default
---
```{r}
getwd()
setwd("C:\\Users\\vicen\\Documents\\R\\predictive_modelling\\predictive_modelling")
```
```{r, echo = TRUE}
# Define the data path and filename
data.path <- "./data"
data.fn <- "sim-modeling-dataset.csv"

```
## Slide with R Output

```{r cars, echo = TRUE}
#summary(cars)
source("fns.R")
```

## Slide con viñetas  y codigo
Alternativa: 
```{r}
# Define columnn class for dataset
colCls <- c("integer",         # row id
            "character",       # analysis year
            "numeric",         # exposure
            "character",       # new business / renewal business
            "numeric",         # driver age (continuous)
            "character",       # driver age (categorical)
            "character",       # driver gender
            "character",       # marital status
            "numeric",         # years licensed (continuous)
            "character",       # years licensed (categorical)
            "character",       # ncd level
            "character",       # region
            "character",       # body code
            "numeric",         # vehicle age (continuous)
            "character",       # vehicle age (categorical)
            "numeric",         # vehicle value
            "character",       # seats
            rep("numeric", 6), # ccm, hp, weight, length, width, height (all continuous)
            "character",       # fuel type
            rep("numeric", 3)  # prior claims, claim count, claim incurred (all continuous)
)

# read in the data with the appropriate column classes
dta <- read.csv(paste(data.path, data.fn, sep = "/"),
                colClasses = colCls)

```

## Slide con viñetas  y codigo

- Establecer el directorio de trabajo
```{r, echo = TRUE}
getwd()

```
## Slide con viñetas  y codigo
- Establecer los datos

## Slide con viñetas  y codigo
- Carga de datos:
Exercise 1.1. Prepare your computing environment. Download the comma-delimited
dataset sim-modeling-dataset.csv and load it into your environment.
```{r}
library(readr)
sim_modeling_dataset <- read_csv("data/sim-modeling-dataset.csv")
#View(sim_modeling_dataset)
```

## Slide with Plot

```{r pressure}
plot(pressure)
```

## Slide with Bullets

- Datos ficticios
- Representan Polizas de automoviles 
- 2010 a 2013
- 40,760 obs y 23 variables
- 5 clases de variables:
  - control, 
  - características del conductor
  - geograficas 
  - características del vehiculo
  - variables de respuesta
  
## Agregación por una variable
```{r}
library(dplyr)
by_cyl <- group_by(mtcars, cyl)
summarise(by_cyl, mean(mpg), mean(hp))

```

## 1.3 Exploratory Data Analysis
Distribución de las variables:
- variabilidad
- tipo de valores
- valores perdidos
- relaciones entre las variables

```{r}
rm(list=ls())
```
Ahora carga de nuevo
```{r}
# load the prepared dataset
load("./data/all-data.RData")
```
Tablas descriptivas de frecuencia y severidad.

```{r}
# Create a summary table of frequency and severity
# by analysis period
yr.expo <- with(dta, tapply(exposure, year, sum))
yr.clm.count <- with(dta, tapply(clm.count, year, sum))
yr.clm.incr <- with(dta, tapply(clm.incurred, year, sum))
yr.summary <- cbind(
  exposure = round(yr.expo,1),
  clm.count = yr.clm.count,
  clm.incurred = round(yr.clm.incr,0),
  frequency = round(yr.clm.count / yr.expo, 3),
  severity = round(yr.clm.incr / yr.clm.count, 1))

yr.summary <- rbind(yr.summary,
                    total = c(
                      round(sum(yr.expo),1),
                      sum(yr.clm.count),
                      round(sum(yr.clm.incr),0),
                      round(sum(yr.clm.count)/sum(yr.expo),3),
                      round(sum(yr.clm.incr)/sum(yr.clm.count),1)))

yr.summary <- yr.summary[c(2,3,4,1,5),] #reorder the rows
write.csv(yr.summary,"freq_sev_anual.csv")
```
Limpieza del espacio de trabajo.

```{r}
# Clean the global environment
rm(yr.expo, yr.clm.count, yr.clm.incr, yr.summary)
```
Evolución del número de coverturas (por exposición) entre periodos.

```{r}
#
# Volume of business over the years
expo <- with(dta, tapply(exposure, year, sum))
round(expo["2012"] / expo["2010"] - 1, 2)
round(expo["2013"] / expo["2012"] - 1, 2)
```


```{r}
# Clean the workspace
rm(expo)

```
### 1.3.1 EDA de Frecuencia

#### Ex 1.2 Frecuencia para el 60 % en la tabla de calibración (entrenamiento)
Frecuencia en la tabla de datos
Se definió aleatoriamente con un generador de numeros aleatorios las observaciones de entrenamiento y de validación.

```{r}
tmp <- subset(dta, subset = train, select = c("exposure", "clm.count"))
ex <- with(tmp, sum(exposure))
cc <- with(tmp, sum(clm.count))
fq <- cc / ex
```

```{r}
#clean up the workspace
rm(tmp, ex, cc, fq)
```
Re-muestreo
```{r}
M <- 1000 # do calcs this many times
fq <- numeric(M) # store frequency
for(i in 1:M) {
u <- runif(40760, min = 0, max = 1)
fq[i] <- with(dta[u < 0.6, ], sum(clm.count) / sum(exposure))
}
library(MASS)
truehist(fq, xlab = "Frequency over re-sampled training dataset")
```

#### Ex 1.3 Frecuencia por región 
estable?
```{r}
#
# Empirical frequency across entire dataset by region
ex <- with(dta, tapply(exposure, region, sum))
cc <- with(dta, tapply(clm.count, region, sum))
f <- sort(round((cc / ex)*100, 1))
plot(f)
```


```{r}
# Clean up the workspace
rm(ex, cc, f)

```

### por edad 
```{r}
#
# Driver age simple characteristics over training dataset
tmp <- sort(unique(dta$driver.age[dta$train]))
diff(tmp)
length(tmp)
```


```{r}
# clean up
rm(tmp)
```


```{r}
# Unique ages over entire dataset
length(unique(dta$driver.age))
setdiff(unique(dta$driver.age), unique(dta$driver.age[dta$train]))
```
Frecuencia descriptivos

```{r}
#
# Empirical frequency for driver age across the training dataset
tmp <- subset(dta, subset = train, select = c("driver.age", "exposure", "clm.count"))
ex <- with(tmp, tapply(exposure, driver.age, sum))
cc <- with(tmp, tapply(clm.count, driver.age, sum))
fr <- round((cc / ex)*100, 1)
summary(fr)
```

```{r}
drage <- sort(unique(tmp$driver.age))
df <- data.frame(ex,cc,fr,drage)
```

Frecuencia directa:

```{r}
library(ggplot2)

ggplot(df, aes(x = ex, y = fr)) +                            # bar plot
  geom_col(size = 1, color = "darkblue", fill = "white")
```


```{r}
ggplot(df) + 
  geom_col(aes(x = drage, y = ex), size = 1, color = "darkblue", fill = "white") +
  geom_line(aes(x = drage, y = fr), size = 1.5, color="red", group = 1) +
  scale_y_continuous(sec.axis = sec_axis(~./10))
 
```



```{r}
# Which ages have frequencies greater than 100%?
nm <- names(fr[which(fr > 100)])
```
Frecuencia máxima y las polizas con mayores frecuencias
```{r}
# What is the data?
tmp[tmp$driver.age %in% nm,]

# sort freq
sort(fr, decreasing = TRUE)[1:5]

# Data with frequency greater than 50% but smaller than 90%
nm <- names(fr[which((fr > 90) & (fr < 100))])
tbl <- tmp[tmp$driver.age %in% nm, c("exposure", "clm.count")]
tbl
apply(tbl, 2, sum)

# show zig-zag pattern
fr[as.character(30:34)]
fr[as.character(50:70)]
fr[as.character(43:53)]
```

#### Ex 1.5 Exposición para mayores de 76

```{r}
#table(dta$drv.age)
tmp <- subset(dta, subset = train & (drv.age == "76"))
tmp[, c("row.id", "exposure", "clm.count")]
apply(tmp[, c("row.id", "exposure", "clm.count")], 2, sum)
rm(tmp) # clean your workspace
```


```{r}
# Clean up the workspace
rm(tmp, ex, cc, fr, nm, tbl)

```

```{r}
#
# Empirical frequency by size of engine for the entire dataset
bk <- unique(quantile(dta$ccm, probs = seq(0, 1, by = 0.05)))
bk[1] <- bk[1] - 1
ccm.d <- cut(dta$ccm, breaks = bk)
expo <- with(dta, tapply(exposure, ccm.d, sum))
clms <- with(dta, tapply(clm.count, ccm.d, sum))
freq <- round(clms / expo*100,2)
freq
```


```{r}
# Clean the workspace
rm(bk, ccm.d, expo, clms, freq)
```

